"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[405],{2470(n,e,r){r.r(e),r.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-2-digital-twin","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"Overview","source":"@site/docs/module-2-digital-twin.md","sourceDirName":".","slug":"/module-2-digital-twin","permalink":"/physical-ai-textbook/docs/module-2-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/hamza49699/physical-ai-textbook/tree/main/docs/module-2-digital-twin.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 2 Introduction: The Digital Twin (Gazebo & Unity)","permalink":"/physical-ai-textbook/docs/module-2-intro"},"next":{"title":"Module 3 Introduction: The AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/physical-ai-textbook/docs/module-3-intro"}}');var s=r(4848),a=r(8453);const t={sidebar_position:2},l="Module 2: The Digital Twin (Gazebo & Unity)",o={},c=[{value:"Overview",id:"overview",level:2},{value:"2.1 Introduction to Gazebo",id:"21-introduction-to-gazebo",level:2},{value:"Installation",id:"installation",level:3},{value:"Launch Your First Simulation",id:"launch-your-first-simulation",level:3},{value:"2.2 Physics Simulation",id:"22-physics-simulation",level:2},{value:"Key Physics Concepts",id:"key-physics-concepts",level:3},{value:"Creating a Simulated Environment",id:"creating-a-simulated-environment",level:3},{value:"Launching Gazebo with ROS 2",id:"launching-gazebo-with-ros-2",level:3},{value:"2.3 Sensor Simulation",id:"23-sensor-simulation",level:2},{value:"LiDAR (Light Detection and Ranging)",id:"lidar-light-detection-and-ranging",level:3},{value:"Depth Camera",id:"depth-camera",level:3},{value:"IMU (Inertial Measurement Unit)",id:"imu-inertial-measurement-unit",level:3},{value:"Reading Sensor Data in ROS 2",id:"reading-sensor-data-in-ros-2",level:3},{value:"2.4 Unity for High-Fidelity Rendering",id:"24-unity-for-high-fidelity-rendering",level:2},{value:"Setting Up ROS 2 in Unity",id:"setting-up-ros-2-in-unity",level:3},{value:"2.5 Human-Robot Interaction Scenarios",id:"25-human-robot-interaction-scenarios",level:2},{value:"Simulating a Robot Greeting Visitor",id:"simulating-a-robot-greeting-visitor",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(n){const e={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"module-2-the-digital-twin-gazebo--unity",children:"Module 2: The Digital Twin (Gazebo & Unity)"})}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(e.p,{children:["A ",(0,s.jsx)(e.strong,{children:"Digital Twin"})," is a virtual replica of your robot in a simulated environment. You can test algorithms, train behaviors, and generate synthetic data without risking expensive hardware."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"What you'll learn:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Physics simulation using Gazebo"}),"\n",(0,s.jsx)(e.li,{children:"High-fidelity 3D rendering with Unity"}),"\n",(0,s.jsx)(e.li,{children:"Simulating realistic sensors (LiDAR, Depth Cameras, IMUs)"}),"\n",(0,s.jsx)(e.li,{children:"Human-robot interaction scenarios"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"21-introduction-to-gazebo",children:"2.1 Introduction to Gazebo"}),"\n",(0,s.jsx)(e.p,{children:"Gazebo is the industry standard for robotics simulation, featuring realistic physics and sensor models."}),"\n",(0,s.jsx)(e.h3,{id:"installation",children:"Installation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Ubuntu 22.04\r\nsudo apt-get update\r\nsudo apt-get install gazebo-11 ros-humble-gazebo-ros-pkgs\r\nsource /opt/ros/humble/setup.bash\n"})}),"\n",(0,s.jsx)(e.h3,{id:"launch-your-first-simulation",children:"Launch Your First Simulation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"gazebo --verbose  # Starts with 3D view\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Resources:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"http://gazebosim.org/tutorials",children:"Gazebo Tutorials"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://github.com/ros-simulation/gazebo_ros_pkgs",children:"ROS 2 + Gazebo Integration"})}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"22-physics-simulation",children:"2.2 Physics Simulation"}),"\n",(0,s.jsx)(e.h3,{id:"key-physics-concepts",children:"Key Physics Concepts"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Concept"}),(0,s.jsx)(e.th,{children:"Definition"}),(0,s.jsx)(e.th,{children:"Example"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Gravity"})}),(0,s.jsx)(e.td,{children:"Force pulling objects down (9.81 m/s\xb2)"}),(0,s.jsx)(e.td,{children:"Robot falls when unsupported"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Collision"})}),(0,s.jsx)(e.td,{children:"Physical objects can't overlap"}),(0,s.jsx)(e.td,{children:"Robot can't walk through walls"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Friction"})}),(0,s.jsx)(e.td,{children:"Resistance between surfaces"}),(0,s.jsx)(e.td,{children:"Robot feet grip the ground"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:(0,s.jsx)(e.strong,{children:"Inertia"})}),(0,s.jsx)(e.td,{children:"Resistance to acceleration"}),(0,s.jsx)(e.td,{children:"Heavy robots accelerate slowly"})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-simulated-environment",children:"Creating a Simulated Environment"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"gazebo_world.sdf (Simulation Description Format)"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0" ?>\r\n<sdf version="1.8">\r\n  <world name="robot_world">\r\n    \r\n    \x3c!-- Physics Configuration --\x3e\r\n    <physics name="default_physics" type="ode">\r\n      <max_step_size>0.001</max_step_size>\r\n      <real_time_factor>1.0</real_time_factor>\r\n      <gravity>0 0 -9.81</gravity>\r\n    </physics>\r\n\r\n    \x3c!-- Ground Plane --\x3e\r\n    <model name="ground_plane">\r\n      <static>true</static>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <plane>\r\n              <normal>0 0 1</normal>\r\n              <size>100 100</size>\r\n            </plane>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <plane>\r\n              <normal>0 0 1</normal>\r\n              <size>100 100</size>\r\n            </plane>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.8 0.8 0.8 1</ambient>\r\n            <diffuse>0.8 0.8 0.8 1</diffuse>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n\r\n    \x3c!-- Obstacles --\x3e\r\n    <model name="wall">\r\n      <static>true</static>\r\n      <pose>5 0 1 0 0 0</pose>\r\n      <link name="link">\r\n        <collision name="collision">\r\n          <geometry>\r\n            <box>\r\n              <size>0.1 10 2</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="visual">\r\n          <geometry>\r\n            <box>\r\n              <size>0.1 10 2</size>\r\n            </box>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.5 0.5 0.5 1</ambient>\r\n            <diffuse>0.5 0.5 0.5 1</diffuse>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"launching-gazebo-with-ros-2",children:"Launching Gazebo with ROS 2"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# In one terminal: Gazebo\r\ngazebo gazebo_world.sdf\r\n\r\n# In another: ROS 2 bridge\r\nros2 run gazebo_ros gazebo_ros_init\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"23-sensor-simulation",children:"2.3 Sensor Simulation"}),"\n",(0,s.jsx)(e.h3,{id:"lidar-light-detection-and-ranging",children:"LiDAR (Light Detection and Ranging)"}),"\n",(0,s.jsx)(e.p,{children:"LiDAR creates a 3D map by shooting laser beams and measuring reflections."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Gazebo URDF with LiDAR Plugin:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<link name="lidar_link">\r\n  <visual>\r\n    <geometry>\r\n      <cylinder radius="0.05" length="0.07"/>\r\n    </geometry>\r\n  </visual>\r\n  <collision>\r\n    <geometry>\r\n      <cylinder radius="0.05" length="0.07"/>\r\n    </geometry>\r\n  </collision>\r\n  <sensor name="lidar_sensor" type="ray">\r\n    <plugin filename="libgazebo_ros_ray_sensor.so" name="gazebo_ros_ray_sensor">\r\n      <ros>\r\n        <remapping>~/out:=/scan</remapping>\r\n      </ros>\r\n      <output_type>sensor_msgs/LaserScan</output_type>\r\n    </plugin>\r\n    <ray>\r\n      <scan>\r\n        <horizontal>\r\n          <samples>360</samples>\r\n          <resolution>1.0</resolution>\r\n          <min_angle>-3.14159</min_angle>\r\n          <max_angle>3.14159</max_angle>\r\n        </horizontal>\r\n      </scan>\r\n      <range>\r\n        <min>0.08</min>\r\n        <max>10.0</max>\r\n        <resolution>0.01</resolution>\r\n      </range>\r\n    </ray>\r\n  </sensor>\r\n</link>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"depth-camera",children:"Depth Camera"}),"\n",(0,s.jsx)(e.p,{children:"Depth cameras measure distance using infrared or structured light."}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<link name="depth_camera_link">\r\n  <sensor name="depth_camera" type="camera">\r\n    <camera>\r\n      <horizontal_fov>1.047</horizontal_fov>\r\n      <image>\r\n        <width>640</width>\r\n        <height>480</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n      <clip>\r\n        <near>0.02</near>\r\n        <far>300</far>\r\n      </clip>\r\n    </camera>\r\n    <plugin filename="libgazebo_ros_camera.so" name="depth_camera_controller">\r\n      <ros>\r\n        <remapping>image_raw:=/depth_camera/image</remapping>\r\n        <remapping>camera_info:=/depth_camera/info</remapping>\r\n      </ros>\r\n      <camera_name>depth_camera</camera_name>\r\n      <frame_name>depth_camera_link</frame_name>\r\n    </plugin>\r\n  </sensor>\r\n</link>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"imu-inertial-measurement-unit",children:"IMU (Inertial Measurement Unit)"}),"\n",(0,s.jsx)(e.p,{children:"IMU measures acceleration and rotation."}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'<link name="imu_link">\r\n  <sensor name="imu_sensor" type="imu">\r\n    <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\r\n      <ros>\r\n        <remapping>imu:=/imu/data</remapping>\r\n      </ros>\r\n      <initial_orientation_as_reference>false</initial_orientation_as_reference>\r\n    </plugin>\r\n  </sensor>\r\n</link>\n'})}),"\n",(0,s.jsx)(e.h3,{id:"reading-sensor-data-in-ros-2",children:"Reading Sensor Data in ROS 2"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import LaserScan, Image\r\nfrom sensor_msgs.msg import Imu\r\n\r\nclass SensorReader(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_reader')\r\n        \r\n        # LiDAR subscriber\r\n        self.lidar_sub = self.create_subscription(\r\n            LaserScan, '/scan', self.lidar_callback, 10)\r\n        \r\n        # Depth camera subscriber\r\n        self.depth_sub = self.create_subscription(\r\n            Image, '/depth_camera/image', self.depth_callback, 10)\r\n        \r\n        # IMU subscriber\r\n        self.imu_sub = self.create_subscription(\r\n            Imu, '/imu/data', self.imu_callback, 10)\r\n\r\n    def lidar_callback(self, msg):\r\n        self.get_logger().info(f\"LiDAR: {len(msg.ranges)} rays\")\r\n        closest = min(msg.ranges)\r\n        self.get_logger().info(f\"Closest obstacle: {closest:.2f}m\")\r\n\r\n    def depth_callback(self, msg):\r\n        self.get_logger().info(f\"Depth camera: {msg.width}x{msg.height}\")\r\n\r\n    def imu_callback(self, msg):\r\n        accel = msg.linear_acceleration\r\n        self.get_logger().info(f\"Acceleration: x={accel.x:.2f}, y={accel.y:.2f}, z={accel.z:.2f}\")\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    rclpy.spin(SensorReader())\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"24-unity-for-high-fidelity-rendering",children:"2.4 Unity for High-Fidelity Rendering"}),"\n",(0,s.jsx)(e.p,{children:"Unity provides photorealistic graphics and can interact with ROS 2 via bridges."}),"\n",(0,s.jsx)(e.h3,{id:"setting-up-ros-2-in-unity",children:"Setting Up ROS 2 in Unity"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Install Unity"})," (2022 LTS recommended)"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Install ROS 2 For Unity"})," package:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'Asset Store \u2192 Search "ROS 2"'}),"\n",(0,s.jsx)(e.li,{children:"Import official ROS 2 For Unity plugin"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Connect to ROS 2:"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing ROS2;\r\n\r\npublic class ROS2Controller : MonoBehaviour\r\n{\r\n    private ROS2Node ros2Node;\r\n    private ISubscription<sensor_msgs.msg.LaserScan> lidarSub;\r\n\r\n    void Start()\r\n    {\r\n        ros2Node = GetComponent<ROS2Node>();\r\n        lidarSub = ros2Node.CreateSubscription<sensor_msgs.msg.LaserScan>(\r\n            "/scan",\r\n            OnLidarData\r\n        );\r\n    }\r\n\r\n    void OnLidarData(sensor_msgs.msg.LaserScan msg)\r\n    {\r\n        Debug.Log($"LiDAR data received: {msg.ranges.Length} rays");\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Resources:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://github.com/RobotecAI/ROS2-for-Unity",children:"Unity + ROS 2 Tutorial"})}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"25-human-robot-interaction-scenarios",children:"2.5 Human-Robot Interaction Scenarios"}),"\n",(0,s.jsx)(e.h3,{id:"simulating-a-robot-greeting-visitor",children:"Simulating a Robot Greeting Visitor"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# interactive_scenario.py\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import Twist\r\nimport time\r\n\r\nclass InteractiveRobot(Node):\r\n    def __init__(self):\r\n        super().__init__(\'interactive_robot\')\r\n        self.cmd_publisher = self.create_publisher(Twist, \'/cmd_vel\', 10)\r\n        \r\n    def greet_visitor(self):\r\n        """Robot detects visitor and waves"""\r\n        self.get_logger().info("Visitor detected! Waving...")\r\n        \r\n        # Wave arm: rotate joint\r\n        twist = Twist()\r\n        twist.angular.z = 0.5  # Wave animation\r\n        \r\n        for _ in range(5):\r\n            self.cmd_publisher.publish(twist)\r\n            time.sleep(0.2)\r\n            twist.angular.z *= -1  # Alternate direction\r\n        \r\n        # Return to rest position\r\n        twist.angular.z = 0.0\r\n        self.cmd_publisher.publish(twist)\r\n        self.get_logger().info("Greeting complete!")\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    robot = InteractiveRobot()\r\n    robot.greet_visitor()\r\n    rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(e.p,{children:["\u2705 ",(0,s.jsx)(e.strong,{children:"Gazebo"})," = Physics-accurate robotics simulation",(0,s.jsx)(e.br,{}),"\n","\u2705 ",(0,s.jsx)(e.strong,{children:"Sensors"})," = LiDAR, Depth cameras, IMUs in simulation",(0,s.jsx)(e.br,{}),"\n","\u2705 ",(0,s.jsx)(e.strong,{children:"Unity"})," = High-fidelity rendering and visualization",(0,s.jsx)(e.br,{}),"\n","\u2705 ",(0,s.jsx)(e.strong,{children:"Digital Twin"})," = Test before deploying to real robots"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Next:"})," Module 3 - AI-Robot Brain (NVIDIA Isaac)"]})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453(n,e,r){r.d(e,{R:()=>t,x:()=>l});var i=r(6540);const s={},a=i.createContext(s);function t(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:t(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);